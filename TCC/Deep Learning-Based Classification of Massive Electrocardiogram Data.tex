\documentclass[journal]{IEEEtran}
\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage{cite}


\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
   \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else

\fi

\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb}  % assumes amsmath package installed
\DeclareMathOperator*{\argmin}{argmin}

\interdisplaylinepenalty=2500
\usepackage{array}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{algpascal}

\usepackage{threeparttable}
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
% Do not put math or special symbols in the title.
%\title{Classification of Massive Electrocardiogram Signals with Autoencoder-Based Deep Neural Network}
\title{Deep Learning-Based Classification of Massive Electrocardiography Data}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{Yan~Yan,~
        Xingbin~Qin,~
        Jianping~Fan,~
        and~Lei~Wang~% <-this % stops a space
\thanks{Y. Yan is with the Shenzhen Key Laboratory for Low-cost Healthcare, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences. No. 1068, Xueyuan Road, Nanshan District,
Shenzhen, Guangdong Province, China-mail: (yan.yan@siat.ac.cn).}% <-this % stops a space
\thanks{X. Qin is with the Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences.
No. 1068, Xueyuan Road, Nanshan District, Shenzhen, Guangdong Province, China.}% <-this % stops a space
\thanks{J. Fan is with the Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences. No. 1068, Xueyuan Road, Nanshan District, Shenzhen, Guangdong Province, China.}% <-this % stops a space
\thanks{L. Wang is with the Shenzhen Key Laboratory for Low-cost Healthcare, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences.
No. 1068, Xueyuan Road, Nanshan District,
Shenzhen, Guangdong Province, China.}% <-this % stops a space
\thanks{Manuscript received September 29, 2014; revised}}


% The paper headers
\markboth{IEEE Transactions on Cloud Computing,~Vol.~, No.~, December~2014}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
A deep learning model based approach for the classification of electrocardiography arrhythmia analysis was presented. Based on massive heartbeat samples extracted from ambulatory ECG dataset, a stacked autoencoder deep neural network structure with pre-training and fine-tuning training method is adopted to classify the normal heartbeat, supraventricular ectopic heartbeat, ventricular ectopic heartbeat, fusion heartbeat labels based on the ANSI/AAMI EC57: 1998/(R)2008 standard. A dataset mainly collected from the subjects in the division of cardiology of the hospital is involved, as well as the MIT-BIH arrhythmia database and MIT-BIH long term ECG database, which are regard as the standard reference for the classifier. The stacked autoencoder algorithm was adopted for feature learning process instead of complex features extraction selection. From the massive unlabeled dataset, features in the ECG samples were acquired. A significant improvement of heartbeat classification from the state-of-the-art is attained for the classification task with the accuracy to $99.34\%$ and ventricular ectopic abnormality sensitivity to 98.31\%. With its self-learning ability, the proposed method has great potential to generalize to other related applications with a large amount of unlabeled data from the long-term clinical monitoring and healthcare monitoring. 

%A Big Data approach for the classification of heartbeat in electrocardiography analysis is presented. Based on massive heartbeat wave samples extracted from ambulatory ECG dataset, a deep neural network structure with a stacked autoencoder pretraining with fine-tuning algorithm is adopted for classification of normal heartbeat, supraventricular ectopic heartbeat, ventricular ectopic heartbeat, fusion heartbeat based on the ANSI/AAMI EC57: 1998/(R)2008 standard. The MIT-BIH arrhythmia database and MIT-BIH long term ECG database are also involved in the database, with the unlabelled database they were divided into three datasets for unsupervised pretraining, supervised fine-tuning and test. From the massive unlabelled dataset, representations learned from the raw sample were acquired by the training algorithm and structure. A significant improvement from the reported results for heartbeat classification is attained for the classification task with the parameters: accuracy to $99.34\%$, normal heartbeat specificity $99.76\%$, supraventricular ectopic heartbeat sensitivity $82.29\%$, ventricular ectopic heartbeat sensitivity $98.31\%$ and fusion heartbeat sensitivity $87.71\%$. 

\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
big data, electrocardiography classification, sparse autoencoder, deep learning, real-time classification.
\end{IEEEkeywords}

% For peer review papers, you can put extra information on the cover
% page as needed:
 \ifCLASSOPTIONpeerreview
 \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
 \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
\IEEEPARstart{A}{n} era of big data in healthcare is now under way, decades of progress in digitising medical records accumulate vast amounts of medical data, simultaneously mobile healthcare and wearable sensor technologies offer healthcare data from larger population coverage.
The noninvasive, inexpensive and well-established technology of electrocardiographic signal in mobile health or personal health has the greatest popularity in heart function analysis.
Automated electrocardiography classification provides indispensable assist in long-term clinical monitoring, and a large number of approaches have been proposed for the task, easing the diagnosis of arrhythmic changes as well as further inspection, e.g., heart rate variability or heart turbulence analysis \cite{mar}. 

Lots of algorithms had been proposed for the classification and detection of electrocardiography signals. 
The electrocardiography classification or detection task had been divided into two parts: the feature extraction process and classifier. 
Simple classifier such as linear discriminants \cite{chaza} and kNN \cite{melgan}, more complex classifiers like neural networks \cite{jiang, olmez, lin, osowski}, fuzzy inference engines \cite{osowski, kundu}, hidden Markov model \cite{andreao, coast}, independent component analysis \cite{zhu} and support vector machine  \cite{melgan, kampoura, khandoker} were also adopted by lots of researchers.  

 
Beyond the classifier, the performance of a recognition system highly depends on the determination of extracted electrocardiography features. Time domain features, frequency domain features, and statistical measures features for six fundamental waves (PQRSTU) had been used in feature extraction process \cite{chia}. 
Time domain features like morphological features include shapes, amplitudes, and durations were adapted primarily in \cite{jekova, christove, can}, frequency domain features like wavelet transformation were widely used \cite{inan}, \cite{banerjee} stationary features like higher-order statistics also had been developed. 
Principal component analysis \cite{stam} and Hermite functions \cite{lager} have been used in electrocardiography classification and related analysis technologies as well.
Almost every single published paper proposes a new set of features to be used, or a new combination of the existing ones \cite{mar}.


The results from these algorithms or models were not amenable to expert labelling, as well as for the identification of complex relationships between subjects and clinical conditions \cite{clifford}.
But for the ambulatory electrocardiography clinical application, as well as the normal application in daily healthcare monitoring for cardiac function or early warning of heart disease, an automated algorithm or model would have significant meaning.
The application of artificial intelligence methods has become an important trend in electrocardiography for the recognition and classification of different arrhythmia types \cite{clifford}. 
The data explosion puts forward the new request to the method of data processing and information mining.


Over the past decades computational techniques proliferated in the pattern recognition field, simultaneously the applications in electrocardiography recognition, detection and classification for relevant trends, patterns, and outliers. 
Most of the literatures in the electrocardiography classification task were focused on the supervised learning methods, as in unsupervised learning methods were infrequently used, which needs a lot of effort in labelling data. The MIT-BIH database \cite{physionet} was the most widely used data in the classification and detection algorithm developments, while mass unlabelled electrocardiography data had been ignored due to the supervise learning approaches essential. 
Unsupervised learning methods become crucial in mining or analysing unlabelled data, as the unlabelled electrocardiography data accumulated. Unsupervised learning-based approaches and the application to electrocardiogram classification in literatures mainly include clustering-based techniques \cite{lager, nishizawa, maier}, self-adaptive neural network-based methods \cite{palreddy, risk} and some hybrid unsupervised learning systems \cite{tadejko}. 

In this paper, we proposed an approach of stacked autoencoder based deep neural network in the unlabelled ambulatory electrocardiography dataset to learn features automatically, with which the cardiac arrhythmia with electrocardiograms classification task was proposed. 

In the following sections, we will first introduce the method and classification task in Section  \uppercase\expandafter{\romannumeral2}  and Section  \uppercase\expandafter{\romannumeral3} . In Section  \uppercase\expandafter{\romannumeral4}  the classification task are proposed, the experiments results would be illustrated in Section  \uppercase\expandafter{\romannumeral5} . Then the discussion are given in Section  \uppercase\expandafter{\romannumeral6} .

\begin{figure*}[]
\centering
\includegraphics[width=7 in]{eps/figure2.eps}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{The autoencoder and the staked autoencoder. (a) the one-layer autoencoder structure with the encoder and decoder for reconstruction of the raw input; (b) the multi-layer stacked autoencoder for input reconstruction; (c) an illustration of the input sample with the reconstruction.}
\label{figure1}
\end{figure*}

\section{Deep Learning, AE and SAE}
\subsection{Deep Learning Methods}
The backpropagation neural network architecture had been widely applied since 1989 by its multidimensional mapping ability: any $L_2$ function from $[0, 1]^n$ to $\mathbf{R}^n$ can be implemented to any desired degree of accuracy with a three-layer backpropagation neural network \cite{hecht}. Until 2006, deep architectures have not been discussed much in the machine learning literature, because of poor training and generalisation errors obtained using the standard random initialization of the parameters \cite{bengio2009}. Great successes in speech recognition \cite{hinton2012deep}, image recognition\cite{ciresan2010deep} had been accomplished via this powerful structure due to the proposed proper training algorithms by Hinton\cite{hinton}. Deep learning methods attempt to learn feature hierarchies as higher-level features are formed by the composition of lower-level features. The network structure could be first layer-wise initialized via unsupervised training and then tuned with supervised learning methods. Deep models can generate more abstract features at higher levels than the lower ones,  better results could be achieved when pre-training each layer with an unsupervised learning algorithm, one layer after the other (the so layer-wised manner), starting with the first layer (that directly takes in input the observed $\mathbf{x}$) \cite{bengio2009}.

Different kinds of deep neural network architectures were proposed since the layer-wised training method developed by Hinton. Typical structures include deep belief networks (DBNs)\cite{hinton2006fast}, deep Boltzmann machines (DBMs) \cite{salakhutdinov2009deep}, stacked autoencoders (SAEs) \cite{bengio2007greedy}, and stacked denoising AEs \cite{vincent2010stacked}. The autoencoder based deep learning model and stacked autoencoder as the corresponding architecture.
 
\subsection{Autoencoders}
The first research on the potential benefits of unsupervised learning based pre-training might date back to 1987, in which the first unsupervised autoencoder hierarchies were proposed \cite{ballard1987modular}. The lowest-level autoencoder neural network is a single hidden layer that is trained to map input patterns to themselves. One visible layer of $n$ inputs, one hidden layer of $m$ units and one reconstruction layer of $n$ outputs, as well the activation functions consist the one-hidden-layer autoencoder as illustrated in (a) part of Fig. \ref{figure1}.


In the training process, the input were mapped to the hidden layer and produce the hidden layer output $h\in{\mathbf{R}^m}$ which was called ``encoder". The hidden layer outputs were mapped to the output layer that were the reconstruction of input layer as the right part called ``decoder" (Fig. \ref{figure1}). An autoencoder is trained to encode the input $x\in{\mathbf{R}^n}$ into some representations $h\in{\mathbf{R}^m}$ so that the input can be reconstructed from that representation\cite{bengio2009}, the reconstructed values were denoted as $\hat{x}\in{\mathbf{R}^n}$. Mathematically, these two steps can be formulated as

\begin{equation}
h = f(W_{1}x+b_{1})
\end{equation}

\begin{equation}
\hat{x}= f(\hat{W_{1}} + \hat{b_{1}})
\end{equation}
where $W_1$ and $\hat{W_1}$ denote the input-to-hidden and the hidden-to-output weights, $b_1$ and $\hat{b_1}$ denote the biases. $f(\cdot)$ denotes the activation function that could be a sigmoid function, hyperbolic tangent, and rectified linear function. The autoencoder behaves differently from PCA, which can capture multi-modal aspects of the input distribution (the representation of the input) \cite{jap} due to the applying of these nonlinear activation functions.

Here we use $W$ and $b$ as the general parameters of the weights and biases, we use  $\hat{x}=h_{W,b}$ denote the reconstruction of the input with an autoencoder, the goal of training is to minimize the error between the input $x$ and reconstruction, i.e.,
\begin{equation}
 \mathop{\argmin}_{W,b}{error(x,\hat{x})}
\end{equation}
So the parameters were $W$ and $b$ while the input $x$  given. The error function can be defined in different ways like root mean square etc. Then the general way for stochastic gradient descent to optimize the parameters were:
\begin{equation}
W := W - \alpha \frac{\partial error(x, \hat{x})}{\partial W}
\end{equation}
and
\begin{equation}
b := b - \alpha \frac{\partial error(x, \hat{x})}{\partial b}
\end{equation}
in which $\alpha $ stands for the learning rate. 

After the training process, the ``decoder" part would be removed while the learning features (output of the hidden layer) with weights and biases would be stored, which can be subsequently used for higher layers to produce deeper features.

\subsection{Stacked autoencoder}
Stacking the input and hidden layers of AEs together layer by layer constructs an SAE \cite{chen2014deep}, the reconstruction of the input with the stacking method is illustrated in (b) of Fig. \ref{figure1}. Deeper features could be generated from the raw input which could be adopted in a subsequent classifier. 

For stacked autoencoder, we first train the first layer autoencoder, subsequently the outputs of the previous layers would be used as the input. Train the parameters of each layer individually while freezing parameters for the remainder of the model. This parameter training method was called greedy layer-wise training \cite{bengio2007greedy}.

\section{Electrocardiography Annotation}
The heart is comprised of the myocardium that rhythmically contract and thus drive the circulation of blood throughout the human body. A wave of electrical current passes through the entire heart, which triggers myocardial contraction\cite{clifford}. Electrical propagation spreads over the whole heart in a coordinated pattern generate changes on the body surface potentials which can be measured and illustrated as an electrocardiogram (ECG, or sometimes EKG). Metabolic abnormalities (a lack of oxygen, or ischemia, etc.) and pathological changes of the heart engender a variety of ECG. Consequently, ECG analysis has been a routine part of any complete medical evaluation or healthcare applications. 

Lots of ECG annotation and diagnosis classification techniques had been proposed in industrial circles and academic communities. As the general steps in a classification problem in a machine learning task, the ECG classification includes data collection, preprocessing, feature extraction, and classification with a classifier. Most of the literatures described models that were combined by different classifier with features extracted by different feature extraction algorithms. The ECG classification methods develop at the same pace with the development of classification theories in machine learning and pattern recognition. Due to the particularity in medical data collection and the medical background requirements for data annotation, the developments in ECG classification and detection were not as flourishing as the similar research topics like speech recognition, natural language processing, image recognition, etc. The framework of a classification problem that illustrated in Fig. \ref{figureX}.

\begin{figure*}[]
\centering
\includegraphics[width=7 in]{eps/figureX_classification.eps}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{The technology roadmap of an ECG classification task.}
\label{figureX}
\end{figure*}



\subsection{Data Collection}
Acquiring and storing ECG data were the base for an analyzing task. Errors might creep into an analysis at any possible stage. Thus, not only the acquisition hardware system but also the transmission and storage should be carefully designed. As for the signal acquiring process, different kinds of sample rates might be involved, for common ECG acquisition device the sample rate would be 128Hz, 250Hz, 340Hz or 500Hz even higher. In murine studies, a sampling rate as high as 2kHz is considered sufficiently. Arbitrary resizing would be an ideal procedure to handle with the different sampling rate from a different data source to build the datasets for analysis, which would be adopted in the experiment to keep data consistency.

\subsection{Data Pre-processing}
Before the segmentation and feature extraction process, the ECG signals were pre-processed. As in the procedure of collecting ECG signals, in addition to the ECG signals, the baseline wander (caused by Perspiration, respiration and body movements), power line interference and muscle noise were recorded as well, which had been described in lots of literature\cite{blanco2008ecg}. When the filtering methods were proposed and adopted in the preprocessing, the desired information should not be altered. The ECG typically exhibits persistent features like P-QRS- T morphology and average RR interval, and non-stationary features like individual RR and QT intervals, long-term heart rate trends\cite{clifford}. Possible distortions caused by filtering should be quantified in these features.
The filtered ECG signals then were segmented into individual heartbeat waveforms depends on the detected R peaks in a classification task. The ECG segmentation can be seen as the decoding procedure of an observation sequence regarding beat waveforms\cite{andreao2006ecg}. Dynamic time warping\cite{vullings1998automated}, time warping\cite{vullings1997ecg}, Bayesian framework\cite{sayadi2009model}, hidden Markov models\cite{andreao2006ecg}, weighted diagnostic distortion \cite{zigel2000weighted}, morphology and heartbeat interval based methods\cite{de2004automatic} and genetic methods\cite{gacek2003genetic} had been used in this subtask. The state accuracies were close to 100\%, which would be accurate enough in most online and offline applications.

\subsection{Feature Extraction}
For supervised learning, the general structure of a learning system includes features and classifiers. For the feature part, time domain features like morphological features include shapes, amplitudes, and durations \cite{jekova, christove, can}, frequency domain features like wavelet transformation\cite{inan}, \cite{banerjee} stationary features like higher order statistics were widely used. With these features, lots of classifier solutions have been proposed for the automated systems to annotate the ECG data \cite{osowski, vullings1998automated, sayadi2009model}. Linear discriminate systems \cite{shinwari2012classification}, decision tree based methods \cite{krasteva2014classification, charfi2012comparative}, multilayer perceptron based methods, fuzzy or neuro-fuzzy systems\cite{erhan2009difficulty,vafaie2014heart }, support vector machines classifiers\cite{ubeyli2007ecg} and as well the hybrid systems\cite{homaeinezhad2012ecg, vanitha2013hybrid} were adopted extensively.

\subsection{ECG Arrhythmia}

After the segmentation for the ECG records, we got plenty of ECG waveform samples with variety categories. Since different physiological disorder may be reflected on the different type of abnormal heartbeat rhythms. For the task of classification, it is quite important to determine the classes would be used. In the early literature, there were no unified class labels for an ECG classification problem. The MIT-BIH Arrhythmia Database was the first available set of standard test material for evaluation of arrhythmia detectors; it played an important role in stimulating manufacturers of arrhythmia analyzers to compete by objectively measurable performance. The annotations in the open database for the ECG categories adopted the ANSI/AAMI EC57: 1998/(R)2008 standard AAMI (2008), which recommended to group the heartbeats into five classes: on-ectopic beats (N as the Fig. \ref{figure2} (a)); supraventricular ectopic beat (S as the Fig. \ref{figure2} (b)); ventricular ectopic beat (V as the Fig. \ref{figure2} (c) and (d)); fusion of a V and a N (F); unknown beat type (Q). These classes or labels have been widely used in the ECG classification tasks related literature. The normal beat, supraventricular ectopic beat and the ventricular ectopic beat categories were used much more frequently while the unknown beat type were abandoned because of its clinical valueless.  

\begin{figure}[]
\centering
\includegraphics[width=3.5 in]{eps/figure2_ecg_beats.png}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{Waveforms of the ECG beats: (a) Typical N label for normal beat; (b) Typical S label for congestive heart failure beat; (c) Typical V label of Ventricular tachyarryhthmia beat; (d) Typical V label of atrial fibrillation beat.}
\label{figure2}
\end{figure}


\begin{table*}[]
\begin{center}
\begin{threeparttable}
\caption{AAMI Classes Mapped from MIT-BIH Arrhythmia \& Long-term Database Types}
\label{Table1}
\begin{tabular}{cllllll}
\hline
& AAMI heartbeat classes & N & S & V & F & Q \\
& Description  &Any heartbeat not in & Supraventricular ectopic  & Ventricular ectopic  & Fusion beat & Unknown beat \\
&                     &the S,V,F or Q class & beat   		     & beat	      &	     &          \\
\hline
& MIT-BIH heartbeat  &Normal beat (1)            & Aberrated atrial premature & Ventricular escape & Fusion of ventricular& Paced beat (12)\\
&  types (codes)   &  					  &  beat (11)		    &  beat(10)	            & \& normal beat (6)		      &             \\

&                     &Left bundle branch   &  Nodal (junctional) &Premature ventricular& 	 &  Unclassifiable \\
&                     &block beat (2)            & premature beat (7)    &contraction (5)         &	   & beat (13)   \\

&                     & Right bundle branch & Atrial premature & Ventricular flutter &    &  Fusion of paced  \\
&                     & block beat (3) & contraction (8)     & wave (31) & 	   & and normal (38)  \\

&                     & Nodal escape  & Premature or ectopic & 	     &  &                          \\
&                     & beat (11)	  & supraventricular beat(9) &     &   &     \\

&                     & Atrial escape beat (34)   &  	  				      & 				            & 			      &                          \\
\hline
& MITBIH-AR$^a$(100,687) & 89,925$^b$   & 2,774   & 7,171   & 802    & 15        \\
& MITBIH-LT(667,347) & 600,197  &  150  & 64,090  & 	2,906   & 0       \\

\hline
\end{tabular}
\begin{tablenotes}
\item [a] Recording 102, 104, 107, 217 were removed.
\item [b] The counts listed in the table may differ from other literatures \cite{chaza} due to the computation need.
\end{tablenotes}
\end{threeparttable}

\end{center}
     \end{table*}



%The related experiments in this paper were carried out in two public databased available on Physionet, and a collected unlabelled ambulatory electrocardiography database (unlabelled means there were no electrocardiography experts involved in the interpretation). 

%As Table I illustrated the detail of the MIT-BIH Arrhythmia Database and MIT-BIH Long-term Database which mapped to the AAMI heartbeat classes.



\section{Classification With Deep learning Stacked Autoencoder Structures}
Since the SAE based deep structure was capable of extracting representations for the raw inputs, it is simpler and more convenient to extract the features for ECG classification instead of discovery or create features by researchers. Thought it should be mentioned that for clinical reasons some features from the researchers might be great of importance, the features were limited in the morphology aspect, which lacks the ability to use some importance features in the transform-domain features or statistical representations. Another motivation for the deep features was, in the real use of the long-term ECG monitoring, the variances of the data collection devices and the difference in different objects. For example, different Holter manufactories use different collecting chips, or different analog-to-digital sampling rate, or even different digital signal filter parameters. Another factor is the physiological differences of the objects. According to these factors, using the single morphology or time domain features were insufficient, the probability distribution of a certain class is non-exclusive and has variations over multiple directions in the feature space, which makes it impossible to analyze the waveform point by point in the real complicated situation. More robust and invariant features should be extracted and used in the auto-analysis scenes. It is believed that deep architectures can potentially lead to progressively more abstract features at higher layers of the feature, and more abstract features are invariant to most local changes of the input\cite{bengio2013representation}.

To tackle with these problems, with the stacked autoencoder model the deep invariant features of raw ECG samples can be learned layer by layer. Same as the traditional learning systems, after the feature extracting process, a classifier would be constructed behind the neural network to finish the classification task (Fig. \ref{figure3}). 

\begin{figure}[]
\centering
\includegraphics[width=3.5 in]{eps/figure3_classifier.eps}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{The multi-layer autoencoder with a subsequent classifier.}
\label{figure3}
\end{figure}

\subsection{Hierarchal Pre-training}

\subsubsection{Sparsity}
In order to guarantee the representation expression ability of the model, a sparsity constraint is imposed on the hidden units. Let $a_{j}^{(l)}$ denotes the activation (output of the activation function $f(\cdot)$, in the input layer, $a_i^{(1)}=x_i$), then
\begin{equation}
\hat{\rho}_j = \frac{1}{m} \sum_{i=1}^m [{a_j^{(2)}}{(x^{(i)})}]
\end{equation}
denotes the average activation of hidden unit $j$ (averaged over the training set). Approximately enforce the constraint:

\begin{equation}
\hat{\rho}_j = \rho
\end{equation}
where $\rho$ is a sparsity parameter, typically a small value close to zero (such as $\rho = 0.05$), which means the average activation of each hidden neuron $j$ to be close to zero (0.05 for instance). 
To satisfy the constraint of sparsity, an extra penalty term to the optimization objective that penalized $\hat{\rho}_j $ deviating significantly from $\rho$. The Kullback-Leibler (KL) divergence:

\begin{equation}
 \sum_{j=1}^{s_2}KL(\rho||\hat{\rho}) =  \sum_{j=1}^{s_2}\rho \text{log}{\frac{\rho}{\hat{\rho}_j}}+(1-\rho)\text{log}\frac{1-\rho}{1-\hat{{\rho}_j}}
\end{equation}

\noindent is chosen as the  penalty term. KL-divergence is a standard function for measuring how different two different distributions are. 
\subsubsection{Cost Function}
The first step is to learn a deep feature for the ECG samples via pretraining the SAE hierarchically. In Section II, the outline of training method had been derived. Mathematically, the overall cost function of neural network is denoted by $J(W, b)$ which was defined by:
\begin{equation}
\begin{split}
J(W,b) = [\frac{1}{m}\sum_{i=1}^m(\frac{1}{2}{\|{h_{W,b}(x^{(i)})} - y^{(i)}\|}^2)] \\
+ \frac{\lambda}{2}\sum_{l=1}^{n_l-1} \sum_{i=1}^{s_l} \sum_{j=1}^{s_l+1}{W_{ji}^{(l)}}^2
\end{split}
\end{equation}
in the first part of which is an average sum-of-square error term: $x$ is the input as the training examples; $y$ denotes the output values (in the autoencoder case, $y$ was set as $y=x$); $(x^{(i)}, y^{(i)})$ denotes the $i$-th training example; $W^{(l)}_{(ij)}$ denotes the weights of the connections between unit $j$ in layer $l$, and unit $i$ in layer $l+1$; $b_i^{(l)}$ denotes the bias term associated with unit $i$ in layer $l+1$. For the regularization term that tends to decrease the magnitude of the weights and helps prevent of overfitting: $\lambda$ was adopted as the weight decay parameter while $n_l$ stands for the number of layers, $s_l$ denotes the number of units in layer $l$.
Add the sparsity parameters, in the autoencoder neural network training, the cost function of $J_{sparse}(W,b)$ was defined as:
\begin{equation}
J_{sparse}(W,b) = J(W,b) + \beta \sum_{j=1}^{s_2}KL(\rho||\hat{\rho_j})
\end{equation}
\noindent $\beta$ denotes the weight of the sparsity penalty term. 


\subsubsection{Activation Function}
The nonlinear mapping activation function $f(\cdot)$ is set to be a $sigmoid$ function:
\begin{equation}
f(x) = \frac{1}{1+e^{-x}}
\end{equation}
both in the ``encoder" and ``decoder". While training the autoencoder, the "tied weights" are used with the greedy layer-wise approach. 

\subsubsection{Training}
The stacked autoencoder consists multiple layers of sparse autoencoders in which the outputs of each layer is wired to the inputs of the successive layer. Sequently we use the definitions above, let $W^{(k)}, \hat{W}^{(k)}, b^{(k)}, \hat{b}^{(k)},$ denote the parameters for the $k$-th autoencoder. The encoding step for the stacked autoencoder is given by running the encoding step of each layer forwardly:
\begin{equation}
a^{(l)} = f(z^{(l)})
\end{equation}
\begin{equation}
z^{(l+1)} = W^{(l)}a^{(l)} + b^{(l)}
\end{equation}
The decoding step is given by running the decoding stack of each autoencoder in reverse order (in the reconstruction encoding and decoding structure):
\begin{equation}
a^{(n + l)} = f(z^{(n + l)}) 
\end{equation}
\begin{equation}
z^{(n + l + 1)} = \hat{W}^{(n - l)}a^{(n + l)} + \hat{b}^{(n - l)}
\end{equation}

Our goal is to minimize the cost function $J_{sparse}(W, b)$(with the sparse penalty term) as the function of $W$ and $b$. To train the network, 

After training the network, the reconstruction layers are removed, then stacked autoencoder is constructed with encoders layer by layer. The learned features which we interested in are contained within $a(n)$, which is the activations of the deepest layer of hidden units. 


The vector gives a representation of the input that can be used for classification problems by feeding $a(n)$ to a classifier. First initialize the parameters of $W^{(l)}_{ij}$ and each $b^{(l)}_i$ to random values near zero, and then apply an optimization algorithm such as mini-batch gradient descent. Then the iteration of gradient descent updates of $W$ and $b$ were:
\begin{equation}
W_{ij}^{(l)}  := W_{ij}^{(l)} - \alpha \frac{\partial}{\partial W_{ij}^{(l)}} J_{sparse}(W,b) 
\end{equation}
and
\begin{equation}
b_{i}^{(l)}  := b_{i}^{(l)} - \alpha \frac{\partial}{\partial b_{i}^{(l)}} J_{sparse}(W,b)
\end{equation}
where $\alpha$ is the learning rate.

Given the training example $(x,y)$(here in autoencoder $(x, \hat{x})$), we first run forward to compute the activations of the network, as the output values were the results of hypothesis $h_{W, b}(x)$ as in equation (9). For each node $i$ in layer $l$, let $\delta_i^{(l)}$ denotes the error term, then the output layer is $\delta^{(n_l)}_i $ means the difference between network's activation and $y$ ($\hat{x}$ in autoencoder) and the hidden layer $\delta^{(l)}_i$ based on the weighted average of the error terms of the nodes that uses $a^{(l)}_i$ as an input.

\alglanguage{pseudocode}
\begin{algorithm}
\caption{The Backpropagation Algorithm}
\begin{algorithmic}[1]
\State Random initialize the parameters and adopt the feedforward calculation to compute the activations for layers $L_2$, $L_3$ to the output layer $L_{n_l}$.
\State For the output layer unit $i$,
\begin{equation}
\begin{split}
\delta^{(n_l)}_i = \frac{\partial}{\partial z^{(n_l)}_i}\frac{1}{2} \left\|y - h_{W,b}(x)\right\|^2 \\
= - (y_i - a^{(n_l)}_i) \cdot f'(z^{(n_l)}_i)
\end{split}
\end{equation} 
\State For the hidden layer $l$, 
\begin{equation}
\begin{split}
\delta^{(l)}_i = \left( \sum_{j=1}^{s_{l+1}} W^{(l)}_{ji} \delta^{(l+1)}_j \right) f'(z^{(l)}_i) \\
+ \beta( - \frac{\rho}{\hat\rho_i} + \frac{1-\rho}{1-\hat\rho_i} ) ) f'(z^{(l)}_i)           
\end{split}
\end{equation}
\State Compute the partial derivatives:
\begin{equation}
\frac{\partial}{\partial W_{ij}^{(l)}} J(W,b; x, y) = a^{(l)}_j \delta_i^{(l+1)} 
\end{equation}
\begin{equation}
\frac{\partial}{\partial b_{i}^{(l)}} J(W,b; x, y) = \delta_i^{(l+1)}
\end{equation}
\State Update the parameters:
\begin{equation}
\mathbf W^{(l)} = \mathbf W^{(l)} - \alpha [ (\frac{1}{m} \Delta \mathbf W^{(l)} ) + \lambda \mathbf W^{(l)}] 
\end{equation}
\begin{equation}
\mathbf b^{(l)} = \mathbf b^{(l)} - \alpha [\frac{1}{m} \Delta \mathbf b^{(l)}]
\end{equation}
\end{algorithmic}
\end{algorithm}

\subsection{Fine-tuning and Classification}
To utilize the learned feature integrate the networks structure, we need to fine-tune the pre-trained network, which uses softmax as the output-layer activation. 

\subsubsection{Softmax model}The Softmax ensures the activation of each output unit sums to 1 as the outputs could be considered as a set of conditional probabilities. Softmax Regression is a supervised learning algorithm. We use Softmax regression as the fine tuning treats all layers of a stacked autoencoder as one single model, which we can improve all the weight parameters in one iteration. 

In the softmax regression model, the hypothesis function is set as:
\begin{equation}
h_{\theta}(x^{(i)}) = 
\left[
      \begin{array}{cccccc}
        p(y^{(i)}=1|x^{(i)};\theta) \\
        p(y^{(i)}=2|x^{(i)};\theta) \\
        \vdots \\
        p(y^{(i)}=k|x^{(i)};\theta)
      \end{array}
    \right]
\end{equation}
\begin{equation}
= \frac{1}{\sum_{j=1}^ke^{\theta_j^Tx^{(i)}}}
\left[
      \begin{array}{cccccc}
        e^{\theta_1^Tx^{(i)}}\\
        e^{\theta_2^Tx^{(i)}}\\
        \vdots \\
        e^{\theta_k^Tx^{(i)}}
      \end{array}
    \right]
\end{equation}
in which output a $k$ dimensional vector denotes $k$ estimated probabilities which stand for $k$ different possible value of the probability. $\theta_1, \theta_2, \ldots, \theta_k \in \Re^{n+1}$ are the parameters of the model. The term $\frac{1}{ \sum_{j=1}^{k}{e^{ \theta_j^T x^{(i)} }} }$  normalizes the distribution which sums to one. The cost function in softmax supervised learning is:
\begin{equation}
\begin{split}
J(\theta) = - \frac{1}{m} \left[ \sum_{i=1}^{m} \sum_{j=1}^{k} 1\left\{y^{(i)} = j\right\} \log \frac{e^{\theta_j^T x^{(i)}}}{\sum_{l=1}^k e^{ \theta_l^T x^{(i)} }}  \right] \\
              + \frac{\lambda}{2} \sum_{i=1}^k \sum_{j=0}^n \theta_{ij}^2
\end{split}
\end{equation}
in which $1\{\cdot\}$ is the indicator function.
Use the iterative optimization algorithm such as gradient descent method. Taking derivatives, the gradient is:
\begin{equation}
\nabla_{\theta_j} J(\theta) = - \frac{1}{m} \sum_{i=1}^{m}{ [ x^{(i)} ( 1\{ y^{(i)} = j\}  - p(y^{(i)} = j | x^{(i)}; \theta) ) ]}
\end{equation}
in which  $\nabla_{\theta_j} J(\theta)$ is a vector, so that its $l$-th element is $\frac{\partial J(\theta)}{\partial \theta_{jl}}$ the partial derivative of $J(\theta)$ with respect to the $l$-th element of $\theta_j$.
Perform the update rule $\theta_j := \theta_j - \alpha \nabla_{\theta_j} J(\theta)$ (for each $j=1,\ldots,k$), we can get the parameters.

\subsubsection{Fine-tuning with softmax regression}
The output layer size is set to be the same as the usual four categories of arrhythmia, and the input layer has the same size as the stacked autoencoder learned features. Since the Softmax regression is implemented as a single-layer neural network, it can be merged with the former layers of networks to get a deep classifier. The fine-tuning step would use the whole combined architecture for optimization with the backpropagation algorithm as Algorithm 1 illustrated, which has a small learning rate on the former autoencoder layers due to the unsupervised learning process.


\alglanguage{pseudocode}
\begin{algorithm}
\caption{Stacked Autoencoder with  Softmax Regression}
\begin{algorithmic}[1]
\State \textbf{begin}
	\State \textbf{initialize} training batch size $a$, pretraining learning rate $\alpha$, numbers of layers $n_l$, numbers of neurons in each hidden layer $s_l$, input dimension $X$, classification labels $k$.
	\For {each layer ($1<=l<=n_l$)} 
		\State Construct an autoencoder with  input neurons, hidden neurons.
		\If {l is the first layer(i.e., l=1)}
			\State $\textbf{AE\_in} = X$
			\State $\textbf{AE\_hid} = h[1]$
			\State Set input of the autoencoder to be the raw ECG data sample
		\Else
			\State $\textbf{AE\_in} = h[L-1]$
			\State $\textbf{AE\_hid} =h[L]$
			\State Set input of the autoencoder to be the output of its former layer.
		\EndIf
	\EndFor
\\
	\State \textbf{initialize} AE weight matrix $\mathbf{W}$ with random variables, and biases as zeros.
	\For each pretraining epoch
		\For every mini-batch
			\State Compute reconstruction (based on (12) - (16)):
			\begin{equation}
				\mathbf{z} = f(\hat{\mathbf W}f(\mathbf W\mathbf x+\mathbf b)+\mathbf {\hat{b}})
			\end{equation}
			\State Compute the cost function: $J_{sparse}(W, b)$
			\State Update parameters using (22) - (23).
		\EndFor
	\EndFor
	\State Remove the reconstruction layer.
\\
	\State \textbf{initialize the softmax regression layer} input neurons as $h[n_l]$, output neurons as the labeled class.
	\For {one fine-tuning epoch}
		\For {every mini-batch}
			\State Use the cost function in (26) and the iteration equation in backpropagation algorithm.
		\EndFor
	\EndFor
\State \textbf{end}
\end{algorithmic}
\end{algorithm}







\section{Experimental Results}

In this study, the method adopted is quite different from other ECG classification methods, which extract some features from the segmented ECG samples. This deep network based framework use all the sample points in the ECG samples and let the autoencoder learn the feature by itself.  Traditional systems adopted includes the feature extraction part to extract features by artificial design.

\subsection{Data Source}
Data from the ambulatory electrocardiography database were used in this study, which includes recordings of 100 subjects with arrhythmia along with normal sinus rhythm. The database contains 100 recordings, each containing a 3- lead 24-hour long electrocardiography which were bandpass filtered at 0.1-100Hz and sampled at 128Hz. In this study, only the lead I data were adapted after preprocessing in the classification task. The reference average heart beats for each sample has 97,855 beats for the 24-hour long recording, and the reference arrhythmia average is 1,810 beats which were estimated by a commercial software (this statistics aim to indicate the existence for arrhythmia samples, which should not be consider as a experiment preset).

The MIT-BIH Arrhythmia Database \cite{physionet} contains 48 half- hour recordings each containing two 30-min ECG lead signals (lead A and lead B), sampled at 360Hz. As well only the lead I data were used in the proposed method. In agreement with the AAMI recommended practice, the four recordings with paced beats were removed from the analysis. Five records randomly selected were used to verify the real time application. The remaining recordings were divided into two datasets, with small part of which were used as the training set of the fine-tuning process.

The MIT-BIT Long-term Database is also used in this study for training and verification, which contains 7 long-term ECG recordings (14 to 22 hours each), with manually reviewed beat annotations and sampled at 128Hz. Similarly, the 7 recordings were divided into two datasets, with part used as the fine-tuning training set. A description of the labelled datasets are illustrated in Table  \ref{table2} .


\begin{table}[!htbp]
\begin{center}
\begin{threeparttable}
\caption{Samples after Segementation}

\label{table2}
\begin{tabular}{cccc}
\hline
& Ambulatory ECG Database (AECG) & MITBIH-AR &  MITBIH-LT\\
\hline
& 9,785,500 & 100,687 &  667,343 \\
\hline
\end{tabular}
\end{threeparttable}
\end{center}
\end{table}


\subsection{Data Preprocessing \& Sample Segementation}
Similar to the routine of electrocardiography classification task, the workflow consists of the stages of prepossessing, processing  and the classifying. The prepossessing stage related technologies are not the focus of this study, so the classical methods for prepossessing were adapted, and just a brief introduction of the details would be mentioned. 

In the preprocessing stage, filtering algorithms were adapted to remove the artefact signals from the ECG signal. The signals include baseline wander, power line interference, and high-frequency noise. For the unlabelled database of ambulatory ECG and the MITBIH LT database, the Lead I data were extracted and a resample from 128Hz to 360Hz procedure was adopted for data consistency.

Before the segmentation procedure from the long-time monitoring ECG signalsHeartbeat Detection: For the heartbeat detection, the MIT-BIH database and unlabelled database, the positions of R waves are determined. The provided fiducial points of R wave had been used as the basis of wave segmentation. The details of the implementation of R wave detection would not be described in this study, and a reference for the R wave detection algorithms had been explored in \cite{afonso}.

In the heartbeat segmentation process, the segmentation program of Laguna \cite{sornmo2006electrocardiogram} was adapted, which also had been validated by other related work\cite{chaza}. The segmentation process was focus on the Lead  \uppercase\expandafter{\romannumeral1} of the recordings. After the segmentation for the ambulatory ECG database, three parts of heartbeat samples listed in Table \ref{table2} were acquired for the classification task. As for the pretraining, fine-tuning for our proposed task and comparison, we divided all the samples into three groups: the pretraining group as dataset A, the fine-tuning group as dataset B and test group as dataset C (illustrated in Table \ref{table3}). Samples are chosen randomly from the original AR and LT database, the details of the sample class would be described in the experiment result analysis.

     
\begin{table}[!htbp]
\begin{center}
\begin{threeparttable}
\caption{Samples Dataset Settings}
\label{table3}
\begin{tabular}{ccccc}
\hline
& Dataset & A & B  &  C\\
\hline
& Useage  & Pretraining & Fine-tuning & Test \\
\hline
& Source (samples) & AECG (9,785,500)   &  &   \\
&  & AR (50,193)   & AR (33,663) & AR (16,831) \\
&  & LT (587,347)  & LT (50,000) & LT (30,000) \\
\hline
&Total & 10,423,040 & 83,633 & 46,831 \\
\hline
\end{tabular}
\end{threeparttable}
\end{center}
\end{table}

As the algorithm of the deep structure training illustrated, both unsupervised learning and supervised learning are involved in the training process. The pre-training mainly used the unlabelled data to train the autoencoder parts, which only need to set the outputs equal to the inputs. Training data adopted in the unsupervised learning step include the whole samples from the ambulatory electrocardiography database and parts of the MIT-BHI database samples. In the supervised learning step, the MIT-BHI database samples with labels were adopted.

\subsection{Autoencoder Behaviour and Analysis}
\subsubsection{Reconstruction and the Learned Features}
Single layer AEs are basic building blocks in the model, so we investigate the behavior of one-layer autoencoder. We use a single-layer AE with 100 hidden units. It is shown that the AE do learn a reconstruction of the training sample. We can see that the learned hidden activity retains enough information from the input as part (c) in Fig. \ref{figure1}. Since in the classifier layer, the learned features are 







\begin{figure}[]
\centering
\includegraphics[width=3.5 in]{eps/features.png}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
\caption{The overlay chart of features learned by the deep model.}
\label{figure4}
\end{figure}



\subsubsection{The Classification Test Results}
Test and Classifier Performance Assessment: After the pretraining and fine-tuning process, the deep network parameters were acquired. Then we use the parameters and the test dataset C to predict the class of samples. It is necessary to mention that in A and B, the labeled data used in pre-training and fine-tuning were divided randomly, which satisfy the requirement of Holdout cross-validation scheme so that the test results were meaningful for the classification task performance improvement.
The following statistical parameters of test performance were used in the study:
\begin{enumerate}
\item Specificity: number of correctly classified normal beats over total number of normal beats.
\item Sensitivity: number of correctly classified abnormal beats over total number of the given abnormal beats.
\item Overall classification accuracy: number of correctly classified beats over number of total beat.
\end{enumerate}

We adopt a 4-hidden-layer autoencoder deep model for the feature learning for the classification task. Since the labelled data were divided randomly, in the test dataset C, we have 41,886 normal heartbeats, 559 supraventricular ectopic beats, 4,137 ventricular ectopic beats and 244 fusion heartbeats as illustrated in Table \ref{table4}. Based on the recognition results we got an accuracy of $99.34\%$. For the N class the specificity is $99.74\%$, the sensitivity of S class is $82.29\%$, the sensitivity of V class is $98.31\%$, the sensitivity of F class is $87.71\%$.

\begin{table}[!htbp]
\begin{center}
\begin{threeparttable}
\caption{Test Result for a 4-Hidden-Layer Deep Network}
\label{table4}
\begin{tabular}{cccccccc}
\hline
\multicolumn{6}{r}{Algorithm label} \\
\cline{3-7}
		&  & N & S      & V    & F     & Q   & T\\
\hline
 Reference & N & 41,778 &  38  &  48   & 17  & 5  &  41,886 \\
	label  & S &  93    & 460  &   3   & 1   & 2  &  559\\
		   & V &  52    & 1    & 4,067 & 11  & 6  &  4,137\\
		   & F &  15    & 0    & 13    & 214 & 2  &  244\\
		   & Q &  1     & 0    & 1     & 1   & 1  &  5\\
\hline
\end{tabular}
\begin{tablenotes}
\item The test accuracy is about $99.34\%$.
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}


\subsection{Comparisons with Other Work}
In this study, we proposed a deep learning model based approach for the heartbeat arrhythmia classification, the arrhythmia classification problem had been discussed in lots of literature as the reference listed. Different kinds of performance assessment criteria had been adopted. In the comparison part, we adopt several ordinary indicators for the performance assessment, which brought in the above sections. The accuracies, N-class specificities (N-spe), S-class sensitivities (S-sen), V-class sensitivities (V-sen) and the F-class sensitivities(F-sen) in Table \ref{table5} are presented for the comparison. The percentages are calculated from the literature' test results, in which some of the classes are ignored like \cite{melgan}, we use a $*$ symbol to represent the result are not available. 
In Table \ref{table5}, we use the highest value (2 to 4 hidden layers based structures) for the verification which illustrated in ``proposed" line.

\begin{table}[!htbp]
\begin{center}
\begin{threeparttable}
\caption{Comparisons with Other Work}
\label{table5}
\begin{tabular}{lllllll}
\hline

Approaches            &  Accuracy & N-spe & S-sen & V-sen & F-sen \\
\hline
 Proposed             & \textbf{99.34\%}  & \textbf{99.76\%} &  82.29\% & \textbf{98.31\%} & 87.71\% \\
 Mar\cite{mar}        & 84.63\%  & 84.85\% & 82.90\%  & 86.72\% & 51.55\% \\
 Chazal\cite{chaza}   & 86.19 \% & 86.86\% & \textbf{83.83\%}  & 77.74\% & \textbf{89.43\%} \\
 Melgani\cite{melgan} & 90.52\%  & 89.12\% & *$^a$    & 89.97\% & * \\
 Jiang \cite{jiang}   & 94.51\%  & 98.73\% & 50.59\%  & 86.61\% & 35.78\% \\
\hline
\end{tabular}
\begin{tablenotes}
\item [a] * means the results were not available.
\item [b] The listed percentages are based on the previous described rules.
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}

Through the comparisons in Table \ref{table5}, we can see that the proposed method offers better accuracy of the classification problem. Since accuracies in lots of the literature were good enough, the verification parameter depends on mainly on the normal class detection, but on the contrary with these methods, this approach provided better performance than other kinds of arrhythmia waveforms classes. Especially in the ventricular ectopic beat sensitivity, a quite large improvement had been made by the proposed method.

\section{Discussion and Conclusions}
The deep neural network structure and deep learning algorithms had been widely used in modern computing science especially in Big Data processes, this study proposed one possibility to adopt this method in the health informatics Big Data applications. In this paper, a stacked autoencoder based deep model was proposed for the electrocardiography arrhythmia classification task. It is shown that the features extracted by autoencoder structure are useful in arrhythmia analysis, even increase the accuracy and some abnormalities specification compare with other features like the morphology features or frequency features.

For ECG data arrhythmia classification, the proposed SAE-SR method has been proven to provide statistically better performance than several state-of-art according to the AAMI standard generally. The classification accuracy is 99.34\%, for normal heartbeat the specificity attains 99.76\%, for supraventricular ectopic heartbeat the sensitivity reach 82.29\%, for ventricular ectopic heartbeat the sensitivity achieve 98.31\% and 87.71\% for fusion heartbeat. Especially in the abnormality type of ventricular ectopic heartbeat, the performance is quite a large improvement. Since the SAE model learned features are based on the unlabelled datasets with low percentage for the abnormalities due to the physiological property, the performance could be improved with more training data. Even though the disadvantage of the SAE-SR method is the training time, but the potential of better results for classification and the testing time efficiency are superior to other methods. 


\section*{Acknowledgment}
This study was financed partially by the National 863 Program of China (Grant No. 2012AA02A604), the Next generation communication technology Major project of National S\&T (Grant No. 2013ZX03005013), the Key Research Program of the Chinese Academy of Sciences, and the Guangdong Innovation Research Team Funds for Image-Guided Therapy and Low-cost Healthcare. 
% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi

% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
\bibliographystyle{IEEEtran} % Style BST file
\bibliography{bare_jrnl}  
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{2}

%\bibitem{tanis}
%T.~Mar, S.~Zaunseder, J.P.~Martinez, M.~Llamedo and R.~Poll, \emph{Optimization of electrocardiography Classification by Means of Feature Selection}.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
  
%\bibitem{care}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
  
%\end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

\begin{IEEEbiography}{Yan Yan}
received the B.eng. degree in the Harbin Institute of Technology, Wei Hai, and the master of engineering in the Harbin Institute of Technology in 2010 and 2012, respectively. He was a research assistance in the Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences from 2012 to 2014. Since 2014 he start pursuing his doctor's degree of computer science. His current research interests include digital signal processing, machine learning and biomedical engineering.
\end{IEEEbiography} 

\begin{IEEEbiography}{Xingbin Qin}
Biography text here.
\end{IEEEbiography}

\begin{IEEEbiography}{Jianping Fan}
Biography text here.
\end{IEEEbiography}
\begin{IEEEbiography}{Lei Wang}
received the B.Eng. degree in information and control engineering, and the Ph.D. degree in biomedical engineering from Xian Jiaotong University, Xian, China, in 1995 and 2000, respectively. He was with the University of Glasgow, Glasgow, U.K., and Imperial College London, London, U.K., from 2000 to 2008. He is currently a Full Professor with the Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China. He has published over 200 scientific papers, authored four book chapters, and holds 60 patents. His current research interests include body sensor network, digital signal processing, and biomedical engineering
\end{IEEEbiography}


% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

% that's all folks
\end{document}


