\relax 
\immediate\closeout\minitoc
\let \MiniTOC =N
\citation{clifford2006advanced}
\@writefile{toc}{\contentsline {title}{ECG Annotation and Diagnosis Classification Techniques}{1}}
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{Yan Yan, Yige Wu, Xinbing Qin, Lei Wang}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{1}}
\citation{mar2011optimization}
\@writefile{toc}{\contentsline {section}{\numberline {2}Technology Roadmap}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The technology roadmap of an ECG classification task.}}{2}}
\newlabel{fig:1}{{1}{2}}
\citation{clifford2006web}
\citation{silva2011dsp}
\citation{ai1996studies}
\citation{blanco2008ecg}
\citation{clifford2006advanced}
\citation{andreao2006ecg}
\citation{vullings1998automated}
\citation{vullings1997ecg}
\citation{sayadi2009model}
\citation{andreao2006ecg}
\citation{zigel2000weighted}
\citation{de2004automatic}
\citation{gacek2003genetic}
\citation{mark1982annotated}
\citation{moody1990bih}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}ECG Acquisition}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}ECG Signal Preprocessing}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}ECG Feature Extraction and Classification}{3}}
\citation{osowski2001ecg}
\@writefile{toc}{\contentsline {section}{\numberline {3}Supervised learning Methods in ECG classification}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Supervised learning methods for ECG annotations}}{4}}
\newlabel{tab:0}{{1}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Unsupervised learning Methods in ECG classification}{4}}
\citation{erhan}
\citation{collobert}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces An overview of the basic steps constituting a clustering process}}{5}}
\newlabel{fig:2}{{2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Deep Learning in ECG Classification: A Preliminary Study Based on Deep Sparse Autoencoder}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Deep Neural Networks}{5}}
\citation{hinton2006reducing}
\citation{duda2012pattern}
\citation{bengio2007greedy}
\citation{bengio2009learning}
\citation{duda2012pattern}
\citation{bishop2006pattern}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Autoencoders and Sparsity}{6}}
\citation{zou2012deep}
\citation{ufldl}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Representation Learning}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Fine-tuning and Classifier}{8}}
\citation{ngiam2011optimization}
\citation{de2004automatic}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Experiments and Results}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.1}Datasets Preparation}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Samples after Segementation}}{10}}
\newlabel{tab:1}{{2}{10}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Samples Dataset Settings}}{11}}
\newlabel{tab:2}{{3}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.2}Classification Workflow}{11}}
\citation{melgan}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.3}Classifier Performance Assessment}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.4}Results}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Test Result for 2-Hidden-Layer Autoencoder Network}}{12}}
\newlabel{tab:3}{{4}{12}}
\citation{mar}
\citation{chaza}
\citation{melgan}
\citation{jiang}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Test Results for 3-Hidden-Layer Autoencoder Network}}{13}}
\newlabel{tab:4}{{5}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Test Results for 4-Hidden-Layer Autoencoder Network}}{13}}
\newlabel{tab:5}{{6}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.5.5}Comparison with Other Work}{13}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Comparisons with Other Work Using Deep Autoencoder}}{13}}
\newlabel{tab:6}{{7}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Deep Learning in ECG Classification: A Two-lead ECG Classification Based on Deep Belief Network}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}The Deep Belief Network and Classifier}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}The Restricted Boltzmann Machine}{14}}
\citation{Leon}
\citation{Hinton02}
\citation{Peng}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Classifier and the Training of Multi-layer RBM}{15}}
\citation{Juergen}
\citation{Bengio2009}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The RBMs are stacked to from a deep belief network(DBN). The RBM can be trained layer by layer. It is easy to construct a DBN with the trained RBMs. Also, a softmax model to fine-tune all parameters behind the last layer.}}{16}}
\newlabel{fig:2}{{3}{16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.3}Combined optimization algorithm for multi-lead classifiers}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Experiment and Results}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Preprocessing and Segmentation}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Training and Fine-tuning}{18}}
\citation{Andreao}
\citation{Asl}
\citation{Melgani}
\citation{Sung}
\citation{Tadejko}
\citation{Banerjee}
\citation{Can}
\citation{Osowski}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Experiment Results}{19}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Test result of three hidden Layers deep belief network using the first lead}}{19}}
\newlabel{tab:7}{{8}{19}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Test result of three hidden Layers deep belief network using the first lead}}{20}}
\newlabel{tab:8}{{9}{20}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Test result of three hidden Layers deep belief network using the first lead}}{20}}
\newlabel{tab:9}{{10}{20}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Comparisons with others' works}}{20}}
\newlabel{tab:10}{{11}{20}}
\citation{Osowski}
\citation{Can}
\bibcite{clifford2006advanced}{1}
\bibcite{ai1996studies}{2}
\bibcite{andreao2006ecg}{3}
\@writefile{toc}{\contentsline {section}{Appendix}{21}}
\@writefile{toc}{\contentsline {section}{References}{21}}
\@mtwritefile{\contentsline {mtchap}{References}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces If the width of the figure is less than 7.8 cm use the \texttt  {sidecapion} command to flush the caption on the left side of the page. If the figure is positioned at the top of the page, align the sidecaption with the top of the figure -- to achieve this you simply need to use the optional argument \texttt  {[t]} with the \texttt  {sidecaption} command}}{21}}
\newlabel{fig:1}{{4}{21}}
\bibcite{bengio2009learning}{4}
\bibcite{bengio2007greedy}{5}
\bibcite{bishop2006pattern}{6}
\bibcite{blanco2008ecg}{7}
\bibcite{clifford2006web}{8}
\bibcite{collobert}{9}
\bibcite{de2004automatic}{10}
\bibcite{duda2012pattern}{11}
\bibcite{erhan}{12}
\bibcite{gacek2003genetic}{13}
\bibcite{hinton2006reducing}{14}
\bibcite{mar2011optimization}{15}
\bibcite{mark1982annotated}{16}
\bibcite{moody1990bih}{17}
\bibcite{ufldl}{18}
\bibcite{ngiam2011optimization}{19}
\bibcite{sayadi2009model}{20}
\bibcite{silva2011dsp}{21}
\bibcite{vullings1998automated}{22}
\bibcite{vullings1997ecg}{23}
\bibcite{zigel2000weighted}{24}
\bibcite{zou2012deep}{25}
\immediate\closeout\minitoc
